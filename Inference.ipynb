{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47029ea0-7341-4d0f-9519-eab98c9dca5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/workspace/cache/\"\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from utils.prompter import Prompter\n",
    "from time import time\n",
    "from time import perf_counter\n",
    "from peft import PeftModel\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, GenerationConfig, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33b9cb-3a85-4e68-9301-aeb465b7fa2c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device_map = {'model.embed_tokens': 0,\n",
    " 'model.layers.0': 0,\n",
    " 'model.layers.1': 0,\n",
    " 'model.layers.2': 0,\n",
    " 'model.layers.3': 0,\n",
    " 'model.layers.4': 0,\n",
    " 'model.layers.5': 0,\n",
    " 'model.layers.6': 0,\n",
    " 'model.layers.7': 0,\n",
    " 'model.layers.8': 0,\n",
    " 'model.layers.9': 0,\n",
    " 'model.layers.10': 0,\n",
    " 'model.layers.11': 0,\n",
    " 'model.layers.12': 0,\n",
    " 'model.layers.13': 0,\n",
    " 'model.layers.14': 0,\n",
    " 'model.layers.15': 0,\n",
    " 'model.layers.16': 0,\n",
    " 'model.layers.17': 0,\n",
    " 'model.layers.18': 0,\n",
    " 'model.layers.19': 0,\n",
    " 'model.layers.20': 0,\n",
    " 'model.layers.21': 0,\n",
    " 'model.layers.22': 0,\n",
    " 'model.layers.23': 0,\n",
    " 'model.layers.24': 0,\n",
    " 'model.layers.25': 0,\n",
    " 'model.layers.26': 0,\n",
    " 'model.layers.27': 0,\n",
    " 'model.layers.28': 0,\n",
    " 'model.layers.29': 0,\n",
    " 'model.layers.30': 1,\n",
    " 'model.layers.31': 1,\n",
    " 'model.layers.32': 1,\n",
    " 'model.layers.33': 1,\n",
    " 'model.layers.34': 1,\n",
    " 'model.layers.35': 1,\n",
    " 'model.layers.36': 1,\n",
    " 'model.layers.37': 1,\n",
    " 'model.layers.38': 1,\n",
    " 'model.layers.39': 1,\n",
    " 'model.layers.40': 1,\n",
    " 'model.layers.41': 1,\n",
    " 'model.layers.42': 1,\n",
    " 'model.layers.43': 1,\n",
    " 'model.layers.44': 1,\n",
    " 'model.layers.45': 1,\n",
    " 'model.layers.46': 1,\n",
    " 'model.layers.47': 1,\n",
    " 'model.layers.48': 1,\n",
    " 'model.layers.49': 1,\n",
    " 'model.layers.50': 1,\n",
    " 'model.layers.51': 1,\n",
    " 'model.layers.52': 1,\n",
    " 'model.layers.53': 1,\n",
    " 'model.layers.54': 1,\n",
    " 'model.layers.55': 1,\n",
    " 'model.layers.56': 1,\n",
    " 'model.layers.57': 1,\n",
    " 'model.layers.58': 1,\n",
    " 'model.layers.59': 1,\n",
    " 'model.layers.60': 1,\n",
    " 'model.layers.61': 1,\n",
    " 'model.layers.62': 1,\n",
    " 'model.layers.63': 1,\n",
    " 'model.layers.64': 1,\n",
    " 'model.layers.65': 1,\n",
    " 'model.layers.66': 1,\n",
    " 'model.layers.67': 1,\n",
    " 'model.layers.68': 1,\n",
    " 'model.layers.69': 1,\n",
    " 'model.layers.70': 1,\n",
    " 'model.layers.71': 1,\n",
    " 'model.layers.72': 1,\n",
    " 'model.layers.73': 1,\n",
    " 'model.layers.74': 1,\n",
    " 'model.layers.75': 1,\n",
    " 'model.layers.76': 1,\n",
    " 'model.layers.77': 1,\n",
    " 'model.layers.78': 1,\n",
    " 'model.layers.79': 1,\n",
    " 'model.norm': 1,\n",
    " 'lm_head': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3f705-ff31-4ac2-b532-4603dae87441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"timdettmers/guanaco-65b-merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b90b53-e3d7-4717-a3ba-869de4129602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\",\n",
    "       load_in_4bit=True,\n",
    "        device_map='auto',\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type='nf4'\n",
    "        ),\n",
    "    )\n",
    "\n",
    "#model = PeftModel.from_pretrained(\n",
    "#            model,\n",
    "#            \"timdettmers/guanaco-7b\",\n",
    "#            torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd8c60-753f-4960-81fd-d3bea42a2058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fa555-0ea7-49ff-a889-5172f1c29b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#prompter = Prompter(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6374bf1-ce6c-47a1-b8a0-8293ef150af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"Résume ce texte issue d'un cours de droit en conservant les dates, les abréviations et les principes importants.\"\n",
    "input=\"\"\"Il arrive également que la garde juridique soit la conséquence de la loi. C’est notamment le cas des tuteurs chargés de gérer le mode de vie de l’enfant placé sous tutelle :\n",
    "Chambre criminelle, 28 mars 2000 : Un enfant de 14 ans est placé sous la tutelle de son beau-père après avoir perdu ses deux parents et en manipulant une arme l’enfant cause la mort d’un camarade. La cour d’appel écarte la faute de surveillance du beau-père mais retient sa responsabilité sur le fondement de l’article 1242 alinéa 1er en sa qualité de tuteur. La Cour de cassation rejette le pourvoi.\"\"\"\n",
    "prompt = prompter.generate_prompt(instruction, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd2653-94e1-4ae5-ac47-a3753a482307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"They\", return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811c91c-5328-4372-9b72-9eef7d9605f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_num_threads(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e166a-1432-47d8-82bf-b69186cde606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=0.1,\n",
    "    use_cache=False\n",
    ")\n",
    "now = time()\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        #generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=100,\n",
    "    )\n",
    "duration = time() - now\n",
    "try:\n",
    "    s = generation_output.sequences[0]\n",
    "except:\n",
    "    s = generation_output[0]\n",
    "\n",
    "tks = (s.shape[0] - input_ids.shape[1])/duration\n",
    "print(f\"{tks} tokens/s\")\n",
    "print(f\"{1/tks} tokens/s\")\n",
    "output = tokenizer.decode(s)\n",
    "print(output)\n",
    "#res = prompter.get_response(output)\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5575b-a317-4c75-b872-74732d00a4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d785b9-e0b4-4ab3-95ea-252da7e85713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155898c-d0bc-42d4-9941-cebf4d46afc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1_start = perf_counter()\n",
    "logits = model(input_ids).logits[:, -1, :]\n",
    "t1_stop = perf_counter()\n",
    "print(f\"{1/(t1_stop - t1_start)} tokens/s\")\n",
    "print(torch.cuda.max_memory_allocated() / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeef77b-393e-4612-892e-83789ac7078c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151329e6-a663-4d04-af84-963e5373682c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1694a2b-2785-4fc1-a737-8d61d4f34088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(generation_output.sequences[1], skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb62f1-0e8b-42c3-a0e5-a0ba1f881957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_output.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf477770-8e95-4df2-a398-4a9fdb63c5de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
