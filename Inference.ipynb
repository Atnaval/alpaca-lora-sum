{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47029ea0-7341-4d0f-9519-eab98c9dca5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/workspace/cache/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from utils.prompter import Prompter\n",
    "from time import time\n",
    "from time import perf_counter\n",
    "from peft import PeftModel\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, GenerationConfig, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3f705-ff31-4ac2-b532-4603dae87441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-30b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b90b53-e3d7-4717-a3ba-869de4129602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-30b-hf\",\n",
    "       load_in_8bit=True,\n",
    "        device_map='auto',\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "            model,\n",
    "            \"./model/checkpoint-300\",\n",
    "            torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd8c60-753f-4960-81fd-d3bea42a2058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### model.eval()\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177fa555-0ea7-49ff-a889-5172f1c29b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "prompter = Prompter(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6374bf1-ce6c-47a1-b8a0-8293ef150af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"Résume ce texte issue d'un cours de droit en conservant les dates, les abréviations et les principes importants.\"\n",
    "input=\"\"\"Cet élément est également appelé l’élément moral de la faute puisqu’il permettait de moraliser les comportements. En effet on ne peut sanctionner que les personnes aptes à comprendre la portée de leur acte et donc de les éviter. Plus exactement, cette conception de la faute empêchait de retenir la responsabilité de deux catégories de personnes privées de discernement. Tout d’abord les majeurs atteinte d’un trouble mental qui les empêche de discerner les conséquences de leurs actes mais surtout les enfants en bas âge, privés de discernement. On estimait que la faculté de discernement était atteinte vers l’âge de 7 ans et qu’en-deçà ne discernait pas les conséquences de ses actes.\"\"\"\n",
    "prompt = prompter.generate_prompt(instruction, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd2653-94e1-4ae5-ac47-a3753a482307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"My name is \", return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e166a-1432-47d8-82bf-b69186cde606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0,\n",
    "    top_p=0.75,\n",
    "    use_cache=False,\n",
    "    do_sample=True\n",
    ")\n",
    "now = time()\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        #generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=100,\n",
    "    )\n",
    "duration = time() - now\n",
    "try:\n",
    "    s = generation_output.sequences[0]\n",
    "except:\n",
    "    s = generation_output[0]\n",
    "\n",
    "tks = (s.shape[0] - input_ids.shape[1])/duration\n",
    "print(f\"{tks} tokens/s\")\n",
    "print(f\"{1/tks} tokens/s\")\n",
    "output = tokenizer.decode(s)\n",
    "#print(output)\n",
    "#res = prompter.get_response(output)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c3d25-26bf-4c9c-9ea6-5f7891a5ac85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
